{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MunkhjargalBayarkhuu/DiveIntoCode-EmpaSoft-Course/blob/master/SimpleConv2d_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rpHk2EcPK6qz"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MB8VA73FK6q3"
      },
      "outputs": [],
      "source": [
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(\"int\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lMgH2_JrK6q5"
      },
      "outputs": [],
      "source": [
        "class FC:\n",
        "\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, dropout_rate=0.5):\n",
        "        self.optimizer = optimizer\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "        self.dZ = 0\n",
        "        self.dA = 0\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.mask = None\n",
        "        self.input_X_forward = 0\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.input_X_forward = X\n",
        "        A = np.dot(X, self.W) + self.B\n",
        "\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA):\n",
        "\n",
        "        dW = np.dot(self.input_X_forward.T, dA)\n",
        "        dZ = np.dot(dA, self.W.T)\n",
        "        self.dA = dA\n",
        "        self.dW = dW\n",
        "        self.dZ = dZ\n",
        "        self = self.optimizer.update(self)\n",
        "        return dZ\n",
        "\n",
        "    def dropout_forward(self, X, flag):\n",
        "        if flag:\n",
        "            self.mask = np.random.rand(*X.shape) > self.dropout_rate\n",
        "            return X * self.mask\n",
        "        else:\n",
        "            return X * (1.0 - self.dropout_rate)\n",
        "\n",
        "    def dropout_backward(self, X):\n",
        "        return X * self.mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MElf2a-JK6q6"
      },
      "outputs": [],
      "source": [
        "class FC2:\n",
        "\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, dropout_rate=0.5):\n",
        "        self.optimizer = optimizer\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "        self.W_feedback = 0\n",
        "        self.B_feedback = 0\n",
        "        self.dZ = 0\n",
        "        self.dA = 0\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.mask = None\n",
        "        self.input_X_forward = 0\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.input_X_forward = X\n",
        "        A = np.dot(X, self.W) + self.B\n",
        "\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA):\n",
        "        dW = np.dot(self.input_X_forward.T, dA)\n",
        "        dZ = np.dot(dA, self.W.T)\n",
        "        self.dA = dA\n",
        "        self.dW = dW\n",
        "        self.dZ = dZ\n",
        "\n",
        "        self.W_feedback = self.dW / self.dA.shape[0]\n",
        "        self.B_feedback = np.average(self.dA, axis=0)\n",
        "        self = self.optimizer.update(self)\n",
        "        return dZ\n",
        "\n",
        "    def dropout_forward(self, X, flag):\n",
        "        if flag:\n",
        "            self.mask = np.random.rand(*X.shape) > self.dropout_rate\n",
        "            return X * self.mask\n",
        "        else:\n",
        "            return X * (1.0 - self.dropout_rate)\n",
        "\n",
        "    def dropout_backward(self, X):\n",
        "        return X * self.mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ruQrmY7QK6q6"
      },
      "outputs": [],
      "source": [
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma = 0.01):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Yrk0OzywK6q7"
      },
      "outputs": [],
      "source": [
        "class SGD:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "\n",
        "        layer.B = layer.B - self.lr * layer.B_feedback\n",
        "        layer.W = layer.W - self.lr * layer.W_feedback\n",
        "\n",
        "        return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WwyIyFwOK6q7"
      },
      "outputs": [],
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        # 初期化\n",
        "        self.input_X_forward = 0\n",
        "\n",
        "    def _func(self, X):\n",
        "        return 1 / (1 + np.exp(-1 * X))\n",
        "\n",
        "    def _func_diff(self, X):\n",
        "        return (1 - self._func(X)) * self._func(X)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.input_X_forward = X\n",
        "        A = self._func(X)\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA):\n",
        "\n",
        "        grad = self._func_diff(self.input_X_forward)\n",
        "        dZ = grad * dA\n",
        "        return dZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "v8yoluVfK6q8"
      },
      "outputs": [],
      "source": [
        "class Tanh:\n",
        "\n",
        "    def __init__(self):\n",
        "        # 初期化\n",
        "        self.input_X_forward = 0\n",
        "\n",
        "    def _func(self, X):\n",
        "        return np.tanh(X)\n",
        "\n",
        "    def _func_diff(self, X):\n",
        "        return 1 - (self._func(X))**2\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.input_X_forward = X\n",
        "        A = self._func(X)\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA):\n",
        "        grad = self._func_diff(self.input_X_forward)\n",
        "        dZ = grad * dA\n",
        "        return dZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "vYUdeJ8pK6q9"
      },
      "outputs": [],
      "source": [
        "class softmax:\n",
        "\n",
        "    def __init__(self):\n",
        "        # 初期化\n",
        "        self.input_X_forward = 0\n",
        "        self.pred = 0\n",
        "\n",
        "    def _func(self, X):\n",
        "        #X = X - np.max(X)\n",
        "        #tmp = np.exp(X)\n",
        "        #denominator = np.sum(tmp, axis=1)\n",
        "        #output = tmp / denominator[:, np.newaxis]\n",
        "        tmp = X - np.max(X)\n",
        "        output = np.exp(tmp) / np.sum(np.exp(tmp))\n",
        "\n",
        "        return output\n",
        "\n",
        "    def _func_diff(self, X):\n",
        "        return X\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.input_X_forward = X\n",
        "        A = self._func(X)\n",
        "        self.pred = A\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA):\n",
        "\n",
        "        dZ = self.pred - dA\n",
        "\n",
        "        return dZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6mvenZkaK6q9"
      },
      "outputs": [],
      "source": [
        "class ReLU:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.input_X_forward = 0\n",
        "\n",
        "    def _func(self, X):\n",
        "        return np.maximum(0, X)\n",
        "\n",
        "    def _func_diff(self, X):\n",
        "        return np.where( X > 0, 1, 0)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.input_X_forward = X\n",
        "        A = self._func(X)\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA):\n",
        "\n",
        "        grad = self._func_diff(self.input_X_forward)\n",
        "        dZ = grad * dA\n",
        "        return dZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Iswcbp3WK6q-"
      },
      "outputs": [],
      "source": [
        "class XavierInitializer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_prev_nodes = 1\n",
        "        pass\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.n_prev_nodes = n_nodes1\n",
        "        W = np.random.randn(n_nodes1, n_nodes2) / np.sqrt(n_nodes1)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = np.random.randn(1, n_nodes2) / np.sqrt(self.n_prev_nodes)\n",
        "        return B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JpHmOk54K6q-"
      },
      "outputs": [],
      "source": [
        "class HeInitializer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_prev_nodes = 1\n",
        "        pass\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.n_prev_nodes = n_nodes1\n",
        "        W = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(2 / n_nodes1)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = np.random.randn(1, n_nodes2) * np.sqrt(2 / self.n_prev_nodes)\n",
        "        return B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zha1LBeAK6q-"
      },
      "outputs": [],
      "source": [
        "class AdaGrad:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.H_B = 1\n",
        "        self.H_W = 1\n",
        "    def update(self, layer):\n",
        "\n",
        "        #dA, dWを更新＆保存\n",
        "        self.H_B = self.H_B + np.average(layer.dA)**2\n",
        "        self.H_W = self.H_W + np.average(layer.dW)**2\n",
        "\n",
        "        layer.B = layer.B - self.lr * np.average(layer.dA, axis=0) / np.sqrt(self.H_B)\n",
        "        layer.W = layer.W - self.lr * layer.dW / layer.dA.shape[0] / np.sqrt(self.H_W)\n",
        "\n",
        "        return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ya21ZsavK6q_"
      },
      "outputs": [],
      "source": [
        "class Conv2d():\n",
        "\n",
        "    def __init__(self, n_input_hight, n_input_width, f_w, f_b, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.n_input_hight = n_input_hight\n",
        "        self.n_input_width = n_input_width\n",
        "        self.W = f_w    #(n_output, n_ch, f_size_h, f_size_w)\n",
        "        self.B = f_b    #(1, n_ch, n_output)\n",
        "        self.n_output = self.W.shape[0]\n",
        "        self.n_input_ch = self.W.shape[1]\n",
        "        self.f_hight = f_w.shape[2]\n",
        "        self.f_width = f_w.shape[3]\n",
        "        self.n_output_hight = self.n_input_hight - self.f_hight + 1\n",
        "        self.n_output_width = self.n_input_width - self.f_width + 1\n",
        "        self.input_X_forward = 0\n",
        "        self.output_X_forward = np.zeros((self.W.shape[0], self.n_output_hight))\n",
        "        self.W_feedback = np.zeros_like(self.W)\n",
        "        self.B_feedback = np.zeros_like(self.B)\n",
        "        self.Z_feedback = 0\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.input_X_forward = X\n",
        "        batch_size = self.input_X_forward.shape[0]\n",
        "        A = np.zeros((batch_size, self.n_output, self.n_input_ch, self.n_output_hight, self.n_output_width))\n",
        "        B = self.B[0]\n",
        "        B = B.T\n",
        "        B = B[np.newaxis]\n",
        "        X = X[:,np.newaxis]\n",
        "        for h in range(self.n_output_hight):\n",
        "            h1 = h\n",
        "            h2 = h + self.f_hight\n",
        "            for w in range(self.n_output_width):\n",
        "                w1 = w\n",
        "                w2 = w + self.f_width\n",
        "                X_seg = X[:,:,:,h1:h2,w1:w2]\n",
        "                tmp = np.sum(np.sum(X_seg * self.W, axis=4), axis=3)\n",
        "                tmp = tmp + B\n",
        "                A[:,:,:,h,w] = tmp\n",
        "\n",
        "        output = np.sum(A, axis=2)\n",
        "        return output\n",
        "\n",
        "    def backward(self, dA):\n",
        "\n",
        "        batch_size = self.input_X_forward.shape[0]\n",
        "        X = np.tile(self.input_X_forward, (dA.shape[1] ,1 ,1))\n",
        "        dL = np.zeros((batch_size, X.shape[1], dA.shape[2], dA.shape[3]))\n",
        "        for i in range(self.n_output):\n",
        "            o1 = i * self.n_input_ch\n",
        "            o2 = i * self.n_input_ch + self.n_input_ch\n",
        "            tmp = dA[:,i][:,np.newaxis]\n",
        "            dL[:,o1:o2] = np.tile(tmp, (self.n_input_ch,1 ,1))\n",
        "\n",
        "        loop1 = self.n_input_hight - self.n_output_hight + 1\n",
        "        loop2 = self.n_input_width - self.n_output_width + 1\n",
        "        dW_tmp = np.zeros((batch_size, X.shape[1], loop1, loop2))\n",
        "        for h in range(loop1):\n",
        "            h1 = h\n",
        "            h2 = h + self.n_output_hight\n",
        "            for w in range(loop2):\n",
        "                w1 = w\n",
        "                w2 = w + self.n_output_width\n",
        "                dX_seg = X[:,:, h1:h2, w1:w2]\n",
        "                dW_tmp[:,:,h,w] = np.sum(np.sum(dL * dX_seg, axis=3), axis=2)\n",
        "\n",
        "        dW_tmp2 = np.average(dW_tmp, axis=0)\n",
        "        for i in range(self.n_output):\n",
        "            o1 = i * self.n_input_ch\n",
        "            o2 = i * self.n_input_ch + self.n_input_ch\n",
        "            self.W_feedback[i] = dW_tmp2[o1:o2]\n",
        "\n",
        "        dB = np.sum(np.sum(dA, axis=3), axis=2)\n",
        "        dB = np.average(dB, axis=0)\n",
        "        for i in range(self.n_input_ch):\n",
        "            self.B_feedback[:,i] = dB\n",
        "\n",
        "        self.Z_feedback = np.zeros_like(self.input_X_forward)\n",
        "        for i in range(self.n_output):\n",
        "            dA_tmp = dA[:,i][:,np.newaxis,:]\n",
        "            dA_padding = np.zeros([batch_size, 1, self.f_hight-1, dA_tmp.shape[3]])\n",
        "            dA_tmp = np.concatenate((dA_tmp, dA_padding), axis=2)\n",
        "            dA_tmp = np.concatenate((dA_padding, dA_tmp), axis=2)\n",
        "\n",
        "            dA_padding = np.zeros([batch_size, 1, dA_tmp.shape[2], self.f_width-1])\n",
        "            dA_tmp = np.concatenate((dA_tmp, dA_padding), axis=3)\n",
        "            dA_tmp = np.concatenate((dA_padding, dA_tmp), axis=3)\n",
        "            dA_tmp = np.tile(dA_tmp, (self.n_input_ch ,1))\n",
        "            dZ_seg = np.zeros_like(self.Z_feedback)\n",
        "\n",
        "            for h in range(self.n_input_hight):\n",
        "                h1 = h\n",
        "                h2 = h + self.f_hight\n",
        "                for w in range(self.n_input_width):\n",
        "                    w1 = w\n",
        "                    w2 = w + self.f_width\n",
        "\n",
        "                    dA_seg = dA_tmp[:,:,h1:h2, w1:w2]\n",
        "\n",
        "                    dA_seg = np.fliplr(np.fliplr(dA_seg).T).T\n",
        "                    tmp = np.sum(np.sum(dA_seg * self.W[i], axis=3), axis=2)\n",
        "                    dZ_seg[:,:,h,w] = tmp\n",
        "\n",
        "            self.Z_feedback += dZ_seg\n",
        "\n",
        "        self = self.optimizer.update(self)\n",
        "        return self.Z_feedback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CadetcC5K6q_"
      },
      "outputs": [],
      "source": [
        "optimizer = SGD(0.01)\n",
        "initializer = XavierInitializer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "MXBq-TWtK6q_"
      },
      "outputs": [],
      "source": [
        "w = np.ones([2,2,2,2])\n",
        "b = np.ones([1,2,2])\n",
        "A = np.random.randint(0,10,(1,2,6,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "SEcUWI-SK6q_"
      },
      "outputs": [],
      "source": [
        "Cov = Conv2d(6,8,w,b,initializer,optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "kEUDqUGTK6rA"
      },
      "outputs": [],
      "source": [
        "dA = Cov.forward(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFW8JlyvK6rA",
        "outputId": "13df3a39-77d0-4509-ffcb-e7d1364b964d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[8, 5, 9, 9, 0, 5, 4, 1],\n",
              "         [9, 9, 5, 5, 4, 1, 7, 6],\n",
              "         [7, 2, 6, 9, 1, 4, 6, 4],\n",
              "         [7, 3, 2, 6, 6, 1, 8, 6],\n",
              "         [4, 9, 2, 0, 1, 7, 0, 4],\n",
              "         [0, 1, 4, 8, 9, 9, 1, 3]],\n",
              "\n",
              "        [[1, 2, 6, 0, 2, 5, 6, 8],\n",
              "         [7, 4, 8, 9, 7, 3, 7, 6],\n",
              "         [9, 2, 9, 6, 2, 6, 9, 7],\n",
              "         [7, 8, 7, 6, 5, 1, 1, 4],\n",
              "         [8, 2, 7, 5, 2, 5, 5, 3],\n",
              "         [1, 6, 4, 4, 7, 0, 0, 1]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raVvsJyQK6rB",
        "outputId": "ea2d9dcf-6ad8-45d3-8323-84aee5cced4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[47., 50., 53., 38., 29., 40., 47.],\n",
              "         [51., 47., 59., 45., 30., 45., 54.],\n",
              "         [47., 41., 53., 43., 28., 38., 47.],\n",
              "         [50., 42., 37., 33., 30., 30., 33.],\n",
              "         [33., 37., 36., 38., 42., 29., 19.]],\n",
              "\n",
              "        [[47., 50., 53., 38., 29., 40., 47.],\n",
              "         [51., 47., 59., 45., 30., 45., 54.],\n",
              "         [47., 41., 53., 43., 28., 38., 47.],\n",
              "         [50., 42., 37., 33., 30., 30., 33.],\n",
              "         [33., 37., 36., 38., 42., 29., 19.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "dA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMmgXUGNK6rB",
        "outputId": "5aa7b45a-c7ec-4401-f89c-a07261bbd92c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 94, 194, 206, 182, 134, 138, 174,  94],\n",
              "         [196, 390, 418, 390, 284, 288, 372, 202],\n",
              "         [196, 372, 400, 400, 292, 282, 368, 202],\n",
              "         [194, 360, 346, 332, 268, 252, 296, 160],\n",
              "         [166, 324, 304, 288, 286, 262, 222, 104],\n",
              "         [ 66, 140, 146, 148, 160, 142,  96,  38]],\n",
              "\n",
              "        [[ 94, 194, 206, 182, 134, 138, 174,  94],\n",
              "         [196, 390, 418, 390, 284, 288, 372, 202],\n",
              "         [196, 372, 400, 400, 292, 282, 368, 202],\n",
              "         [194, 360, 346, 332, 268, 252, 296, 160],\n",
              "         [166, 324, 304, 288, 286, 262, 222, 104],\n",
              "         [ 66, 140, 146, 148, 160, 142,  96,  38]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "Cov.backward(dA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "o7TqucuwK6rB"
      },
      "outputs": [],
      "source": [
        "def cal_output_data_size(input_X, filter_W, padding_size_h, padding_size_w, stride_h, stride_w):\n",
        "    input_x_hight = input_X.shape[1]\n",
        "    input_x_width = input_X.shape[2]\n",
        "    output_ch = filter_W[0]\n",
        "    filter_w_hight = filter_W.shape[3]\n",
        "    filter_w_width = filter_W.shape[4]\n",
        "\n",
        "    out_h = (input_x_hight + padding_size_h * 2 - filter_W_hight) / stride_h + 1\n",
        "    out_w = (input_x_width + padding_size_w * 2 - filter_W_width) / stride_w + 1\n",
        "\n",
        "    return out_ch, out_h, out_w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "nD1Xo9ibK6rB"
      },
      "outputs": [],
      "source": [
        "class Max_pooling():\n",
        "\n",
        "    def __init__(self, stride_h, stride_w):\n",
        "        self.h = stride_h\n",
        "        self.w = stride_w\n",
        "        self.max_pos = 0\n",
        "        self.backward_map = 0\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        X.shape (batch_size, ch, h, w)\n",
        "        \"\"\"\n",
        "        batch_size = X.shape[0]\n",
        "        ch_size = X.shape[1]\n",
        "        h_size = X.shape[2]\n",
        "        w_size = X.shape[3]\n",
        "\n",
        "        output_size_h = (int)(h_size / self.h)\n",
        "        output_size_w = (int)(w_size / self.w)\n",
        "        output = np.zeros((batch_size, ch_size, output_size_h, output_size_w))\n",
        "        self.backward_map = np.zeros((batch_size, ch_size, output_size_h, output_size_w, self.h, self.w))\n",
        "\n",
        "\n",
        "        for n_h in range(output_size_h):\n",
        "            for n_w in range(output_size_w):\n",
        "                pos_h1 = n_h + n_h * (self.h - 1)\n",
        "                pos_h2 = pos_h1 + self.h\n",
        "                pos_w1 = n_w + n_w * (self.w - 1)\n",
        "                pos_w2 = pos_w1 + self.w\n",
        "\n",
        "                tmp = np.max(np.max(X[:,:, pos_h1:pos_h2, pos_w1:pos_w2], axis=3), axis=2)\n",
        "                output[:,:, n_h, n_w] = tmp\n",
        "                tmp = tmp[:,:,np.newaxis,np.newaxis]\n",
        "                self.backward_map[:,:, n_h, n_w] = (X[:,:, pos_h1:pos_h2, pos_w1:pos_w2] == tmp)\n",
        "\n",
        "\n",
        "        self.backward_map = self.backward_map.astype(int)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        dA.shape (batch_size, ch, h, w)\n",
        "        \"\"\"\n",
        "        batch_size = dA.shape[0]\n",
        "        ch_size = dA.shape[1]\n",
        "        h_size = dA.shape[2]\n",
        "        w_size = dA.shape[3]\n",
        "\n",
        "        output_size_h = h_size * self.h\n",
        "        output_size_w = w_size * self.w\n",
        "        output = np.zeros((batch_size, ch_size, output_size_h, output_size_w))\n",
        "        for n_h in range(h_size):\n",
        "            for n_w in range(w_size):\n",
        "                pos_h1 = n_h + n_h * (self.h - 1)\n",
        "                pos_h2 = pos_h1 + self.h\n",
        "                pos_w1 = n_w + n_w * (self.w - 1)\n",
        "                pos_w2 = pos_w1 + self.w\n",
        "\n",
        "                tmp = dA[:,:, n_h, n_w][:,:, np.newaxis, np.newaxis]\n",
        "                output[:,:, pos_h1:pos_h2, pos_w1:pos_w2] = tmp * self.backward_map[:,:, n_h, n_w]\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "oe1t9yaOK6rC"
      },
      "outputs": [],
      "source": [
        "p = Max_pooling(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "yDhl9i00K6rC"
      },
      "outputs": [],
      "source": [
        "A = np.random.randint(0,10,(1,3,6,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "sDi67RhJK6rC"
      },
      "outputs": [],
      "source": [
        "dA = p.forward(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duFt1F1gK6rC",
        "outputId": "c81d87d1-5d63-4a50-a453-c20a38ab80d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:\n",
            " [[[[7 5 4 6 2 5 8 9]\n",
            "   [0 0 1 6 5 1 6 3]\n",
            "   [1 7 1 6 5 6 2 8]\n",
            "   [4 7 8 2 9 2 7 2]\n",
            "   [6 2 1 9 0 6 0 4]\n",
            "   [6 3 8 3 3 0 2 0]]\n",
            "\n",
            "  [[3 4 2 2 3 1 3 1]\n",
            "   [7 3 1 8 1 0 2 4]\n",
            "   [7 2 8 0 9 0 6 6]\n",
            "   [0 9 8 2 0 9 1 9]\n",
            "   [7 0 7 4 6 7 3 4]\n",
            "   [8 7 9 6 7 0 5 0]]\n",
            "\n",
            "  [[5 7 7 6 2 1 5 6]\n",
            "   [1 3 5 5 6 4 9 7]\n",
            "   [6 2 0 7 2 9 0 6]\n",
            "   [6 4 8 2 0 2 7 2]\n",
            "   [3 9 7 1 3 2 8 9]\n",
            "   [6 7 5 8 3 3 1 6]]]]\n",
            "output:\n",
            " [[[[7. 6. 5. 9.]\n",
            "   [7. 8. 9. 8.]\n",
            "   [6. 9. 6. 4.]]\n",
            "\n",
            "  [[7. 8. 3. 4.]\n",
            "   [9. 8. 9. 9.]\n",
            "   [8. 9. 7. 5.]]\n",
            "\n",
            "  [[7. 7. 6. 9.]\n",
            "   [6. 8. 9. 7.]\n",
            "   [9. 8. 3. 9.]]]]\n"
          ]
        }
      ],
      "source": [
        "print(\"input:\\n\",A)\n",
        "print(\"output:\\n\",dA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkb1bhrtK6rC",
        "outputId": "aa5c2ad7-cffe-4f0f-bc29-05e75bffc7cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[7., 0., 0., 6., 0., 5., 0., 9.],\n",
              "         [0., 0., 0., 6., 5., 0., 0., 0.],\n",
              "         [0., 7., 0., 0., 0., 0., 0., 8.],\n",
              "         [0., 7., 8., 0., 9., 0., 0., 0.],\n",
              "         [6., 0., 0., 9., 0., 6., 0., 4.],\n",
              "         [6., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 3., 0., 0., 0.],\n",
              "         [7., 0., 0., 8., 0., 0., 0., 4.],\n",
              "         [0., 0., 8., 0., 9., 0., 0., 0.],\n",
              "         [0., 9., 8., 0., 0., 9., 0., 9.],\n",
              "         [0., 0., 0., 0., 0., 7., 0., 0.],\n",
              "         [8., 0., 9., 0., 7., 0., 5., 0.]],\n",
              "\n",
              "        [[0., 7., 7., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 6., 0., 9., 0.],\n",
              "         [6., 0., 0., 0., 0., 9., 0., 0.],\n",
              "         [6., 0., 8., 0., 0., 0., 7., 0.],\n",
              "         [0., 9., 0., 0., 3., 0., 0., 9.],\n",
              "         [0., 0., 0., 8., 3., 3., 0., 0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "p.backward(dA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5iKg2TtlK6rD"
      },
      "outputs": [],
      "source": [
        "class Flatten2():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.input_X_shape = 0\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        X.shape (batch_size, n_output, n_feature1, n_feature2)\n",
        "\n",
        "        return (batch_size, n_output * n_feature1 * n_feature2)\n",
        "        \"\"\"\n",
        "        self.inout_X_shape = X.shape\n",
        "        output = X.reshape([self.inout_X_shape[0], self.inout_X_shape[1] * self.inout_X_shape[2] * self.inout_X_shape[3]])\n",
        "        return output\n",
        "\n",
        "    def backward(self, X):\n",
        "        output = X.reshape(self.inout_X_shape)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3jsYi2hlK6rD"
      },
      "outputs": [],
      "source": [
        "default_dnn_design = {\n",
        "    'learning_rate':0.001,\n",
        "    'total_layer':3,\n",
        "    'func_layer1':'tanh',\n",
        "    'func_layer2':'tanh',\n",
        "    'func_layer3':'softmax',\n",
        "    'node_layer0':786,\n",
        "    'node_layer1':400,\n",
        "    'node_layer2':200,\n",
        "    'node_layer3':10,\n",
        "    'initializer':'SimpleInitializer',\n",
        "    'initializer_sigma':0.05,\n",
        "    'optimizer':'SGD',\n",
        "}\n",
        "\n",
        "class ScratchDeepNeuralNetrowkClassifier2():\n",
        "\n",
        "    def __init__(self, n_epoch, batch_size, verbose = False):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = batch_size\n",
        "        self.n_epoch = n_epoch\n",
        "        self.loss = 0\n",
        "        self.loss_val = 0\n",
        "        self.activation_func = 0\n",
        "        self.affine_func = 0\n",
        "        self.n_layer = 0\n",
        "        self.layer_instance = [0 for _ in range(64)]\n",
        "\n",
        "\n",
        "    def _crossentropy(self, y_pred, y):\n",
        "        INF_AVOIDANCE = 1e-8\n",
        "        cross_entropy = -1 * y * np.log(y_pred + INF_AVOIDANCE)\n",
        "        return np.sum(cross_entropy, axis=1)\n",
        "\n",
        "    def add_layer(self, model):\n",
        "        self.layer_instance[self.n_layer] = model\n",
        "        self.n_layer += 1\n",
        "        return\n",
        "\n",
        "    def delet_all_layer(self):\n",
        "        self.layer_instance[0:self.n_layer] = 0\n",
        "        self.n_layer = 0\n",
        "\n",
        "        return\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.loss = [[0 for i in range(X.shape[0])] for j in range(self.n_epoch)]\n",
        "        self.loss_val = [[0 for i in range(X.shape[0])] for j in range(self.n_epoch)]\n",
        "\n",
        "        i = 0\n",
        "        get_mini_batch = GetMiniBatch(x_train, y_train, self.batch_size)\n",
        "        for epoch in range(self.n_epoch):\n",
        "            #print(\"Proceeding Epoch:\", i+1)\n",
        "            loop_count = 0\n",
        "            sum_loss = 0\n",
        "            for mini_X_train, mini_y_train in get_mini_batch:\n",
        "                X = mini_X_train\n",
        "                for layer in range(self.n_layer):\n",
        "                    X = self.layer_instance[layer].forward(X)\n",
        "                    #print(\"layer:{} X:\\n{}\".format(layer, X))\n",
        "\n",
        "                sum_loss += self._crossentropy(X, mini_y_train)\n",
        "\n",
        "                dz = mini_y_train\n",
        "                for layer in reversed(range(0, self.n_layer)):\n",
        "                    dz = self.layer_instance[layer].backward(dz)\n",
        "\n",
        "\n",
        "                loop_count += 1\n",
        "\n",
        "            self.loss[i] = sum_loss / loop_count\n",
        "            if X_val is not None and y_val is not None:\n",
        "                y_val_pred = self._predict(X_val)\n",
        "                self.loss_val[i] = self._crossentropy(y_val_pred, y_val)\n",
        "\n",
        "            if self.verbose:\n",
        "                print(\"Epoch:{} \\n Loss:\\n{} Loss(val):\\n{}\".format(i+1, self.loss[i], self.loss_val[i]))\n",
        "\n",
        "            i +=1\n",
        "\n",
        "        return\n",
        "\n",
        "    def predict(self, X):\n",
        "        for layer in range(self.n_layer):\n",
        "            X = self.layer_instance[layer].forward(X)\n",
        "\n",
        "        max_val = np.max(X, axis=1)\n",
        "        mask = np.ones_like(X)\n",
        "        X[X == max_val[:,np.newaxis]] = 1\n",
        "        X[X != mask] = 0\n",
        "\n",
        "        return X\n",
        "\n",
        "    def _predict(self, X):\n",
        "        for layer in range(self.n_layer):\n",
        "            X = self.layer_instance[layer].forward(X)\n",
        "\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "j2TdcqaUK6rD"
      },
      "outputs": [],
      "source": [
        "class Conv2d():\n",
        "\n",
        "    def __init__(self, n_input_hight, n_input_width, f_w, f_b, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self.n_input_hight = n_input_hight\n",
        "        self.n_input_width = n_input_width\n",
        "        self.W = f_w    #(n_output, n_ch, f_size_h, f_size_w)\n",
        "        self.B = f_b    #(1, n_ch, n_output)\n",
        "        self.n_output = self.W.shape[0]\n",
        "        self.n_input_ch = self.W.shape[1]\n",
        "        self.f_hight = f_w.shape[2]\n",
        "        self.f_width = f_w.shape[3]\n",
        "        self.n_output_hight = self.n_input_hight - self.f_hight + 1\n",
        "        self.n_output_width = self.n_input_width - self.f_width + 1\n",
        "        self.input_X_forward = 0\n",
        "        self.output_X_forward = np.zeros((self.W.shape[0], self.n_output_hight))\n",
        "        self.W_feedback = np.zeros_like(self.W)\n",
        "        self.B_feedback = np.zeros_like(self.B)\n",
        "        self.Z_feedback = 0\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.input_X_forward = X\n",
        "        batch_size = self.input_X_forward.shape[0]\n",
        "        A = np.zeros((batch_size, self.n_output, self.n_input_ch, self.n_output_hight, self.n_output_width))\n",
        "        B = self.B[0]\n",
        "        B = B.T\n",
        "        B = B[np.newaxis]\n",
        "        X = X[:,np.newaxis]\n",
        "        for h in range(self.n_output_hight):\n",
        "            h1 = h\n",
        "            h2 = h + self.f_hight\n",
        "            for w in range(self.n_output_width):\n",
        "                w1 = w\n",
        "                w2 = w + self.f_width\n",
        "                X_seg = X[:,:,:,h1:h2,w1:w2]\n",
        "                tmp = np.sum(np.sum(X_seg * self.W, axis=4), axis=3)\n",
        "                tmp = tmp + B\n",
        "                A[:,:,:,h,w] = tmp\n",
        "\n",
        "        output = np.sum(A, axis=2)\n",
        "        return output\n",
        "\n",
        "    def backward(self, dA):\n",
        "\n",
        "        batch_size = self.input_X_forward.shape[0]\n",
        "        X = np.tile(self.input_X_forward, (dA.shape[1] ,1 ,1))\n",
        "        dL = np.zeros((batch_size, X.shape[1], dA.shape[2], dA.shape[3]))\n",
        "        for i in range(self.n_output):\n",
        "            o1 = i * self.n_input_ch\n",
        "            o2 = i * self.n_input_ch + self.n_input_ch\n",
        "            tmp = dA[:,i][:,np.newaxis]\n",
        "            dL[:,o1:o2] = np.tile(tmp, (self.n_input_ch,1 ,1))\n",
        "\n",
        "        loop1 = self.n_input_hight - self.n_output_hight + 1\n",
        "        loop2 = self.n_input_width - self.n_output_width + 1\n",
        "        dW_tmp = np.zeros((batch_size, X.shape[1], loop1, loop2))\n",
        "        for h in range(loop1):\n",
        "            h1 = h\n",
        "            h2 = h + self.n_output_hight\n",
        "            for w in range(loop2):\n",
        "                w1 = w\n",
        "                w2 = w + self.n_output_width\n",
        "                dX_seg = X[:,:, h1:h2, w1:w2]\n",
        "                dW_tmp[:,:,h,w] = np.sum(np.sum(dL * dX_seg, axis=3), axis=2)\n",
        "\n",
        "        dW_tmp2 = np.average(dW_tmp, axis=0)\n",
        "        for i in range(self.n_output):\n",
        "            o1 = i * self.n_input_ch\n",
        "            o2 = i * self.n_input_ch + self.n_input_ch\n",
        "            self.W_feedback[i] = dW_tmp2[o1:o2]\n",
        "\n",
        "        dB = np.sum(np.sum(dA, axis=3), axis=2)\n",
        "        dB = np.average(dB, axis=0)\n",
        "        for i in range(self.n_input_ch):\n",
        "            self.B_feedback[:,i] = dB\n",
        "\n",
        "        self.Z_feedback = np.zeros_like(self.input_X_forward)\n",
        "        for i in range(self.n_output):\n",
        "            dA_tmp = dA[:,i][:,np.newaxis,:]\n",
        "            dA_padding = np.zeros([batch_size, 1, self.f_hight-1, dA_tmp.shape[3]])\n",
        "            dA_tmp = np.concatenate((dA_tmp, dA_padding), axis=2)\n",
        "            dA_tmp = np.concatenate((dA_padding, dA_tmp), axis=2)\n",
        "\n",
        "            dA_padding = np.zeros([batch_size, 1, dA_tmp.shape[2], self.f_width-1])\n",
        "            dA_tmp = np.concatenate((dA_tmp, dA_padding), axis=3)\n",
        "            dA_tmp = np.concatenate((dA_padding, dA_tmp), axis=3)\n",
        "            dA_tmp = np.tile(dA_tmp, (self.n_input_ch ,1))\n",
        "            dZ_seg = np.zeros_like(self.Z_feedback)\n",
        "\n",
        "            for h in range(self.n_input_hight):\n",
        "                h1 = h\n",
        "                h2 = h + self.f_hight\n",
        "                for w in range(self.n_input_width):\n",
        "                    w1 = w\n",
        "                    w2 = w + self.f_width\n",
        "\n",
        "                    dA_seg = dA_tmp[:,:,h1:h2, w1:w2]\n",
        "                    dA_seg = np.fliplr(np.fliplr(dA_seg).T).T\n",
        "                    tmp = np.sum(np.sum(dA_seg * self.W[i], axis=3), axis=2)\n",
        "                    dZ_seg[:,:,h,w] = tmp\n",
        "\n",
        "            self.Z_feedback += dZ_seg\n",
        "\n",
        "        self = self.optimizer.update(self)\n",
        "        return self.Z_feedback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asbPPVkFK6rE",
        "outputId": "8458991e-dcc2-4ac3-85c2-19388bbed618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(3000, 1, 28, 28)\n",
            "(57000, 1, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_test = x_test.astype(np.float32)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "\n",
        "\n",
        "x_train = x_train[:,np.newaxis,:]\n",
        "x_test = x_test[:,np.newaxis,:]\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train_one_hot, test_size=0.95)\n",
        "print(x_train.shape) # (48000, 784)\n",
        "print(x_val.shape) # (12000, 784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "pxpX0qUYK6rE"
      },
      "outputs": [],
      "source": [
        "w = np.random.randn(2,1,2,2)\n",
        "b = np.random.randn(1,1,2)\n",
        "A = np.random.randint(0,10,(1,2,6,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "p3uFBP8fK6rE"
      },
      "outputs": [],
      "source": [
        "CNN2 = ScratchDeepNeuralNetrowkClassifier2(10, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "NBPS2ojLK6rE"
      },
      "outputs": [],
      "source": [
        "CNN2.add_layer(Conv2d(x_train.shape[2],x_train.shape[3], w, b, initializer, optimizer))\n",
        "CNN2.add_layer(Flatten2())\n",
        "CNN2.add_layer(FC2(w.shape[0] * (x_train.shape[2] - w.shape[2] + 1) * (x_train.shape[3] - w.shape[3] + 1), 100, initializer, optimizer))\n",
        "CNN2.add_layer(ReLU())\n",
        "CNN2.add_layer(FC2(100, 10, initializer, optimizer))\n",
        "CNN2.add_layer(softmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gRDL4yJK6rF",
        "outputId": "9157886f-90b6-4da9-bfac-7f85a6799ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred=\n",
            " [[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "Yval=\n",
            "   (0, 2)\t1.0\n",
            "  (1, 4)\t1.0\n",
            "  (2, 6)\t1.0\n",
            "  (3, 1)\t1.0\n",
            "  (4, 8)\t1.0\n",
            "  (5, 0)\t1.0\n",
            "  (6, 4)\t1.0\n",
            "  (7, 7)\t1.0\n",
            "  (8, 7)\t1.0\n",
            "  (9, 1)\t1.0\n",
            "  (10, 2)\t1.0\n",
            "  (11, 1)\t1.0\n",
            "  (12, 2)\t1.0\n",
            "  (13, 6)\t1.0\n",
            "  (14, 8)\t1.0\n",
            "  (15, 7)\t1.0\n",
            "  (16, 2)\t1.0\n",
            "  (17, 8)\t1.0\n",
            "  (18, 3)\t1.0\n",
            "  (19, 3)\t1.0\n",
            "  (20, 5)\t1.0\n",
            "  (21, 2)\t1.0\n",
            "  (22, 5)\t1.0\n",
            "  (23, 9)\t1.0\n",
            "  (24, 8)\t1.0\n",
            "  :\t:\n",
            "  (56975, 2)\t1.0\n",
            "  (56976, 5)\t1.0\n",
            "  (56977, 7)\t1.0\n",
            "  (56978, 7)\t1.0\n",
            "  (56979, 5)\t1.0\n",
            "  (56980, 4)\t1.0\n",
            "  (56981, 9)\t1.0\n",
            "  (56982, 7)\t1.0\n",
            "  (56983, 3)\t1.0\n",
            "  (56984, 8)\t1.0\n",
            "  (56985, 2)\t1.0\n",
            "  (56986, 6)\t1.0\n",
            "  (56987, 9)\t1.0\n",
            "  (56988, 1)\t1.0\n",
            "  (56989, 5)\t1.0\n",
            "  (56990, 0)\t1.0\n",
            "  (56991, 7)\t1.0\n",
            "  (56992, 4)\t1.0\n",
            "  (56993, 5)\t1.0\n",
            "  (56994, 1)\t1.0\n",
            "  (56995, 2)\t1.0\n",
            "  (56996, 7)\t1.0\n",
            "  (56997, 3)\t1.0\n",
            "  (56998, 8)\t1.0\n",
            "  (56999, 0)\t1.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Pred=\\n\", y_pred)\n",
        "print(\"Yval=\\n\", y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKR5f7GPK6rF",
        "outputId": "ea9d31ec-e299-4212-ebeb-12da4d531c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score=0.113\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy score={:.3f}\".format(accuracy_score(y_pred, y_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "NTPnLygQK6rP",
        "outputId": "b95f1865-b3a6-49bd-a897-9c73d773ebb6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "loss = np.array(CNN2.loss)\n",
        "loss_ave = np.average(loss, axis=1)\n",
        "\n",
        "loss_val = np.array(CNN2.loss_val)\n",
        "loss_val_ave = np.average(loss_val, axis=1)\n",
        "\n",
        "plt.title(\"epoch vs loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.plot(loss_ave, \"r\", label=\"loss\")\n",
        "plt.plot(loss_val_ave, \"b\", label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "h5iylKz_K6rQ"
      },
      "outputs": [],
      "source": [
        "n_epoch = 10\n",
        "n_batch = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Dtuv7qWtK6rQ"
      },
      "outputs": [],
      "source": [
        "CNN3 = ScratchDeepNeuralNetrowkClassifier2(n_epoch, n_batch, verbose =True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "l6o3go3QK6rQ"
      },
      "outputs": [],
      "source": [
        "conv_w_lenet1 = np.random.randn(6,1,5,5)\n",
        "conv_b_lenet1 = np.random.randn(1,1,6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "4-ogYc1uK6rQ"
      },
      "outputs": [],
      "source": [
        "conv_w_lenet2 = np.random.randn(16,6,5,5)\n",
        "conv_b_lenet2 = np.random.randn(1,6,16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "qcIZvVd_K6rQ"
      },
      "outputs": [],
      "source": [
        "CNN3.add_layer(Conv2d(x_train.shape[2],x_train.shape[3], conv_w_lenet1, conv_b_lenet1, SimpleInitializer(), SGD(0.01)))\n",
        "CNN3.add_layer(ReLU())\n",
        "CNN3.add_layer(Max_pooling(2,2))\n",
        "CNN3.add_layer(Conv2d(12,12, conv_w_lenet2, conv_b_lenet2, SimpleInitializer(), SGD(0.01)))\n",
        "CNN3.add_layer(ReLU())\n",
        "CNN3.add_layer(Max_pooling(2,2))\n",
        "CNN3.add_layer(Flatten2())\n",
        "CNN3.add_layer(FC2(256, 120, SimpleInitializer(), SGD(0.01)))\n",
        "CNN3.add_layer(ReLU())\n",
        "CNN3.add_layer(FC2(120, 84, SimpleInitializer(), SGD(0.01)))\n",
        "CNN3.add_layer(ReLU())\n",
        "CNN3.add_layer(FC2(84, 10, SimpleInitializer(), SGD(0.01)))\n",
        "CNN3.add_layer(softmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LlW4eg1K6rR",
        "outputId": "17b0a283-b3ab-4006-81f0-87d717c1c520"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(57000, 1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "x_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "b8wH-OIoK6rR"
      },
      "outputs": [],
      "source": [
        "y_pred = CNN3.predict(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d854F9vhK6rR",
        "outputId": "bd059615-8962-4feb-96e1-3a471ae784ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score=0.113\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy score={:.3f}\".format(accuracy_score(y_pred, y_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "rFtCTbFdK6rR",
        "outputId": "f70fa697-574b-4f3a-cb6c-478b4205ed6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "loss = np.array(CNN3.loss)\n",
        "loss_ave = np.average(loss, axis=1)\n",
        "\n",
        "loss_val = np.array(CNN3.loss_val)\n",
        "loss_val_ave = np.average(loss_val, axis=1)\n",
        "\n",
        "plt.title(\"epoch vs loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.plot(loss_ave, \"r\", label=\"loss\")\n",
        "plt.plot(loss_val_ave, \"b\", label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "tiNmIotHK6rR"
      },
      "outputs": [],
      "source": [
        "class Max_pooling():\n",
        "\n",
        "    def __init__(self, stride_h, stride_w):\n",
        "        self.h = stride_h\n",
        "        self.w = stride_w\n",
        "        self.max_pos = 0\n",
        "        self.backward_map = 0\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        X.shape (batch_size, ch, h, w)\n",
        "        \"\"\"\n",
        "        batch_size = X.shape[0]\n",
        "        ch_size = X.shape[1]\n",
        "        h_size = X.shape[2]\n",
        "        w_size = X.shape[3]\n",
        "\n",
        "        output_size_h = (int)(h_size / self.h)\n",
        "        output_size_w = (int)(w_size / self.w)\n",
        "        output = np.zeros((batch_size, ch_size, output_size_h, output_size_w))\n",
        "        self.backward_map = np.zeros((batch_size, ch_size, output_size_h, output_size_w, self.h, self.w))\n",
        "\n",
        "        for n_h in range(output_size_h):\n",
        "            for n_w in range(output_size_w):\n",
        "                pos_h1 = n_h + n_h * (self.h - 1)\n",
        "                pos_h2 = pos_h1 + self.h\n",
        "                pos_w1 = n_w + n_w * (self.w - 1)\n",
        "                pos_w2 = pos_w1 + self.w\n",
        "\n",
        "                tmp = np.average(np.average(X[:,:, pos_h1:pos_h2, pos_w1:pos_w2], axis=3), axis=2)\n",
        "                output[:,:, n_h, n_w] = tmp\n",
        "                tmp = tmp[:,:,np.newaxis,np.newaxis]\n",
        "                self.backward_map[:,:, n_h, n_w] = (X[:,:, pos_h1:pos_h2, pos_w1:pos_w2] == tmp)\n",
        "\n",
        "        self.backward_map = self.backward_map.astype(int)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        dA.shape (batch_size, ch, h, w)\n",
        "        \"\"\"\n",
        "        batch_size = dA.shape[0]\n",
        "        ch_size = dA.shape[1]\n",
        "        h_size = dA.shape[2]\n",
        "        w_size = dA.shape[3]\n",
        "\n",
        "        output_size_h = h_size * self.h\n",
        "        output_size_w = w_size * self.w\n",
        "        output = np.zeros((batch_size, ch_size, output_size_h, output_size_w))\n",
        "        for n_h in range(h_size):\n",
        "            for n_w in range(w_size):\n",
        "                pos_h1 = n_h + n_h * (self.h - 1)\n",
        "                pos_h2 = pos_h1 + self.h\n",
        "                pos_w1 = n_w + n_w * (self.w - 1)\n",
        "                pos_w2 = pos_w1 + self.w\n",
        "\n",
        "                tmp = dA[:,:, n_h, n_w][:,:, np.newaxis, np.newaxis]\n",
        "                output[:,:, pos_h1:pos_h2, pos_w1:pos_w2] = tmp * self.backward_map[:,:, n_h, n_w]\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1NExJYCHOhG7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}